{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "535/535 [==============================] - 34s 45ms/step - loss: 34.0733 - mae: 3.8989\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 12.8067 - mae: 2.7404\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 12.3199 - mae: 2.6757\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 22s 40ms/step - loss: 12.0102 - mae: 2.6358\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 20s 36ms/step - loss: 11.5945 - mae: 2.5890\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 21s 39ms/step - loss: 11.2196 - mae: 2.5444\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 22s 42ms/step - loss: 10.9470 - mae: 2.5112\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 10.6262 - mae: 2.4747\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 24s 46ms/step - loss: 10.3966 - mae: 2.4476\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 25s 46ms/step - loss: 10.0735 - mae: 2.4044\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 28s 53ms/step - loss: 9.6335 - mae: 2.3426\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 28s 52ms/step - loss: 9.1883 - mae: 2.2827\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 28s 53ms/step - loss: 9.0538 - mae: 2.2598\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 8.5694 - mae: 2.1912\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 8.2575 - mae: 2.1439\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 7.8777 - mae: 2.0937\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 24s 45ms/step - loss: 7.5308 - mae: 2.0470\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 25s 47ms/step - loss: 7.4996 - mae: 2.0427\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 25s 47ms/step - loss: 6.9598 - mae: 1.9576\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 26s 50ms/step - loss: 6.7334 - mae: 1.9228\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "data = pd.read_csv(\"ETTh1_without_missing.csv\")\n",
    "\n",
    "# Sélection des caractéristiques nécessaires pour l'entraînement\n",
    "OT_values = data[\"OT\"].values\n",
    "\n",
    "# Fonction pour créer les séquences de données\n",
    "def create_sequences(values, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - sequence_length - 100):\n",
    "        X.append(values[i:i + sequence_length])\n",
    "        y.append(values[i + sequence_length:i + sequence_length + 100])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Longueur de la séquence\n",
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "# Création des séquences pour l'entraînement du modèle\n",
    "X_train, y_train = create_sequences(OT_values, SEQUENCE_LENGTH)\n",
    "\n",
    "# # Création du modèle LSTM avec TensorFlow\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.LSTM(64, input_shape=(SEQUENCE_LENGTH, 1)),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(100)  # Un seul neurone de sortie pour prédire la valeur suivante\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(SEQUENCE_LENGTH, 1)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100)  # Neurone de sortie pour prédire la valeur suivante\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs= 20, batch_size=32)\n",
    "\n",
    "# Prédiction des 100 valeurs suivantes\n",
    "last_sequence = OT_values[-SEQUENCE_LENGTH:].reshape(1, SEQUENCE_LENGTH, 1)\n",
    "predicted_values = model.predict(last_sequence).reshape(-1)\n",
    "\n",
    "# Sélection des 100 premières valeurs prédites disponibles\n",
    "num_predicted_values = min(len(predicted_values), 100)\n",
    "predicted_df = pd.DataFrame({'id': range(num_predicted_values), 'OT': predicted_values[:num_predicted_values]})\n",
    "\n",
    "# Écriture dans un nouveau fichier CSV\n",
    "predicted_df.to_csv('OT_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
