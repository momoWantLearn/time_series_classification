{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETTh1_without_missing.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.competition_download_file('time-series-classification-part-1','ETTh1_without_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2016-07-01', 'hour': 0, 'OT': 30.5310001373291}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def get_data_from_csv(path):\n",
    "    row = []\n",
    "    with open(path, 'r') as file:\n",
    "        i = 0\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        data = {}\n",
    "        for row in reader:\n",
    "            if(i != 0):\n",
    "                row_values = {}\n",
    "                row_values[\"date\"] = (row[0].split(\",\"))[1].split(\" \")[0]\n",
    "                row_values[\"hour\"] = int((row[0].split(\",\"))[1].split(\" \")[1].split(\":\")[0])\n",
    "                row_values[\"OT\"] = float((row[0].split(\",\"))[2])\n",
    "                id = int(row[0].split(\",\")[0])\n",
    "                data[id] = row_values\n",
    "            i += 1\n",
    "        return data\n",
    "\n",
    "data = get_data_from_csv('ETTh1_without_missing.csv')\n",
    "print(data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-22 16:00:00\n",
      "2018-06-22 17:00:00\n",
      "2018-06-22 18:00:00\n",
      "2018-06-22 19:00:00\n",
      "2018-06-22 20:00:00\n",
      "2018-06-22 21:00:00\n",
      "2018-06-22 22:00:00\n",
      "2018-06-22 23:00:00\n",
      "2018-06-23 00:00:00\n",
      "2018-06-23 01:00:00\n",
      "2018-06-23 02:00:00\n",
      "2018-06-23 03:00:00\n",
      "2018-06-23 04:00:00\n",
      "2018-06-23 05:00:00\n",
      "2018-06-23 06:00:00\n",
      "2018-06-23 07:00:00\n",
      "2018-06-23 08:00:00\n",
      "2018-06-23 09:00:00\n",
      "2018-06-23 10:00:00\n",
      "2018-06-23 11:00:00\n",
      "2018-06-23 12:00:00\n",
      "2018-06-23 13:00:00\n",
      "2018-06-23 14:00:00\n",
      "2018-06-23 15:00:00\n",
      "2018-06-23 16:00:00\n",
      "2018-06-23 17:00:00\n",
      "2018-06-23 18:00:00\n",
      "2018-06-23 19:00:00\n",
      "2018-06-23 20:00:00\n",
      "2018-06-23 21:00:00\n",
      "2018-06-23 22:00:00\n",
      "2018-06-23 23:00:00\n",
      "2018-06-24 00:00:00\n",
      "2018-06-24 01:00:00\n",
      "2018-06-24 02:00:00\n",
      "2018-06-24 03:00:00\n",
      "2018-06-24 04:00:00\n",
      "2018-06-24 05:00:00\n",
      "2018-06-24 06:00:00\n",
      "2018-06-24 07:00:00\n",
      "2018-06-24 08:00:00\n",
      "2018-06-24 09:00:00\n",
      "2018-06-24 10:00:00\n",
      "2018-06-24 11:00:00\n",
      "2018-06-24 12:00:00\n",
      "2018-06-24 13:00:00\n",
      "2018-06-24 14:00:00\n",
      "2018-06-24 15:00:00\n",
      "2018-06-24 16:00:00\n",
      "2018-06-24 17:00:00\n",
      "2018-06-24 18:00:00\n",
      "2018-06-24 19:00:00\n",
      "2018-06-24 20:00:00\n",
      "2018-06-24 21:00:00\n",
      "2018-06-24 22:00:00\n",
      "2018-06-24 23:00:00\n",
      "2018-06-25 00:00:00\n",
      "2018-06-25 01:00:00\n",
      "2018-06-25 02:00:00\n",
      "2018-06-25 03:00:00\n",
      "2018-06-25 04:00:00\n",
      "2018-06-25 05:00:00\n",
      "2018-06-25 06:00:00\n",
      "2018-06-25 07:00:00\n",
      "2018-06-25 08:00:00\n",
      "2018-06-25 09:00:00\n",
      "2018-06-25 10:00:00\n",
      "2018-06-25 11:00:00\n",
      "2018-06-25 12:00:00\n",
      "2018-06-25 13:00:00\n",
      "2018-06-25 14:00:00\n",
      "2018-06-25 15:00:00\n",
      "2018-06-25 16:00:00\n",
      "2018-06-25 17:00:00\n",
      "2018-06-25 18:00:00\n",
      "2018-06-25 19:00:00\n",
      "2018-06-25 20:00:00\n",
      "2018-06-25 21:00:00\n",
      "2018-06-25 22:00:00\n",
      "2018-06-25 23:00:00\n",
      "2018-06-26 00:00:00\n",
      "2018-06-26 01:00:00\n",
      "2018-06-26 02:00:00\n",
      "2018-06-26 03:00:00\n",
      "2018-06-26 04:00:00\n",
      "2018-06-26 05:00:00\n",
      "2018-06-26 06:00:00\n",
      "2018-06-26 07:00:00\n",
      "2018-06-26 08:00:00\n",
      "2018-06-26 09:00:00\n",
      "2018-06-26 10:00:00\n",
      "2018-06-26 11:00:00\n",
      "2018-06-26 12:00:00\n",
      "2018-06-26 13:00:00\n",
      "2018-06-26 14:00:00\n",
      "2018-06-26 15:00:00\n",
      "2018-06-26 16:00:00\n",
      "2018-06-26 17:00:00\n",
      "2018-06-26 18:00:00\n",
      "2018-06-26 19:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the last value to predict the next 100 values\n",
    "last_entry = data[max(data.keys())]\n",
    "\n",
    "# Extract the date and hour from the last value\n",
    "last_date = datetime.strptime(last_entry['date'], \"%Y-%m-%d\")  # Convert the date string to a datetime object\n",
    "last_hour = last_entry['hour']\n",
    "\n",
    "next_100_dates = []  # List to store the next 100 dates\n",
    "\n",
    "# Generate the next 100 dates\n",
    "for _ in range(100):\n",
    "    last_hour += 1  # Increment the hour by 1\n",
    "    next_date = last_date + timedelta(hours=last_hour)  # Calculate the next date\n",
    "\n",
    "    # Format the next date to the desired string format\n",
    "    next_date_formatted = next_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(next_date_formatted)  # Print the formatted next date\n",
    "    next_100_dates.append(next_date_formatted)  # Append the formatted next date to the list\n",
    "\n",
    "# The list next_100_dates now contains the next 100 dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "extracted_data = {cle: valeur for i, (cle, valeur) in enumerate(data.items()) if i >= len(data)-1000}\n",
    "print(len(extracted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length : 722 samples\n",
      "Validation set length : 128 samples\n",
      "Test set length : 150 samples\n",
      "Total : 1000 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Extract the dates from the data by converting strings to datetime objects\n",
    "dates = [datetime.strptime(value['date'], '%Y-%m-%d') for _, value in extracted_data.items()]\n",
    "\n",
    "# Extract the years, months, days, and hours from the datetime objects\n",
    "years = [date.year for date in dates]\n",
    "months = [date.month for date in dates]\n",
    "days = [date.day for date in dates]\n",
    "hours = [value['hour'] for _, value in extracted_data.items()]\n",
    "\n",
    "# Extract the targets (OT values) from the data\n",
    "targets = [value['OT'] for _, value in extracted_data.items()]\n",
    "\n",
    "# Stack the years, months, days, and hours into a numpy array\n",
    "input = np.column_stack((years, months, days, hours))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# 80% of the data will be used for training and 20% for testing\n",
    "# Data is split randomly, with random_state=42 to ensure reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(input, targets, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(np.array(X_train), np.array(y_train), test_size=0.15, random_state=42)\n",
    "\n",
    "# Create TensorFlow datasets from arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "batch_size_value = 32\n",
    "# Shuffle and batch the training data\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size_value)\n",
    "\n",
    "# Batch the validation and test data\n",
    "val_dataset = val_dataset.batch(batch_size_value)\n",
    "test_dataset = test_dataset.batch(batch_size_value)\n",
    "\n",
    "# Affichage des tailles des ensembles d'entra√Ænement et de test\n",
    "print(\"Train set length :\", len(X_train), \"samples\")\n",
    "print(\"Validation set length :\", len(X_val), \"samples\")\n",
    "print(\"Test set length :\", len(X_test), \"samples\")\n",
    "print(\"Total :\", len(X_train)+len(X_test)+len(X_val), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 13ms/step - loss: 1169.4719 - mae: 25.5299 - val_loss: 134.4894 - val_mae: 11.3449\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 67.6679 - mae: 6.9635 - val_loss: 22.3172 - val_mae: 4.2702\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9.4718 - mae: 2.4413 - val_loss: 7.4728 - val_mae: 2.1749\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.0916 - mae: 1.8987 - val_loss: 6.7403 - val_mae: 1.9935\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1341 - mae: 1.9050 - val_loss: 5.7956 - val_mae: 1.7137\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1627 - mae: 1.9160 - val_loss: 6.9344 - val_mae: 2.0472\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1839 - mae: 1.9201 - val_loss: 6.2066 - val_mae: 1.8459\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1341 - mae: 1.9046 - val_loss: 5.7546 - val_mae: 1.7035\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.2334 - mae: 1.9381 - val_loss: 8.1849 - val_mae: 2.3286\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.7576 - mae: 2.0060 - val_loss: 9.0327 - val_mae: 2.3521\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.6639 - mae: 2.1966 - val_loss: 6.1794 - val_mae: 1.7945\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.5601 - mae: 1.9846 - val_loss: 5.8172 - val_mae: 1.7168\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.0619 - mae: 2.0719 - val_loss: 9.2818 - val_mae: 2.5413\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1941 - mae: 1.9243 - val_loss: 5.7100 - val_mae: 1.6981\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5.8788 - mae: 1.8342 - val_loss: 5.6866 - val_mae: 1.6842\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5.8033 - mae: 1.8359 - val_loss: 5.6768 - val_mae: 1.6867\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.0608 - mae: 2.0654 - val_loss: 7.9805 - val_mae: 2.1476\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.4139 - mae: 1.9471 - val_loss: 5.9593 - val_mae: 1.7870\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1162 - mae: 1.9223 - val_loss: 5.6759 - val_mae: 1.6897\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.5245 - mae: 2.1556 - val_loss: 6.0450 - val_mae: 1.7607\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.4876 - mae: 1.9573 - val_loss: 5.7539 - val_mae: 1.7257\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.0639 - mae: 2.0795 - val_loss: 6.2885 - val_mae: 1.8845\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.3191 - mae: 1.9479 - val_loss: 6.9831 - val_mae: 1.9544\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.2472 - mae: 1.9189 - val_loss: 5.7172 - val_mae: 1.7123\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.3070 - mae: 1.9556 - val_loss: 7.5852 - val_mae: 2.2122\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5.9170 - mae: 1.8640 - val_loss: 5.7748 - val_mae: 1.7415\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.2845 - mae: 1.9549 - val_loss: 5.6395 - val_mae: 1.6873\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.0104 - mae: 1.8543 - val_loss: 5.9436 - val_mae: 1.7990\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.0108 - mae: 1.8941 - val_loss: 6.1353 - val_mae: 1.8544\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1043 - mae: 1.8743 - val_loss: 8.1909 - val_mae: 2.3371\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.6211 - mae: 1.9628 - val_loss: 6.1114 - val_mae: 1.8491\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.1114 - mae: 1.8984 - val_loss: 5.8185 - val_mae: 1.6948\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.0382 - mae: 1.9005 - val_loss: 7.0478 - val_mae: 2.0884\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.3974 - mae: 2.1808 - val_loss: 5.7754 - val_mae: 1.7501\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.2902 - mae: 2.1054 - val_loss: 5.6570 - val_mae: 1.7071\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9.0265 - mae: 2.3784 - val_loss: 10.1302 - val_mae: 2.6804\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8.0684 - mae: 2.2477 - val_loss: 7.5742 - val_mae: 2.2116\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.3260 - mae: 2.1096 - val_loss: 8.8732 - val_mae: 2.2947\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.2866 - mae: 2.1125 - val_loss: 9.3159 - val_mae: 2.5383\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.5939 - mae: 1.9870 - val_loss: 11.8911 - val_mae: 2.9589\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.5777 - mae: 1.9972 - val_loss: 5.8775 - val_mae: 1.7919\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.3259 - mae: 1.9351 - val_loss: 6.1691 - val_mae: 1.8791\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.4941 - mae: 1.9531 - val_loss: 6.6386 - val_mae: 1.8672\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9.2770 - mae: 2.4317 - val_loss: 9.8898 - val_mae: 2.6351\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.8901 - mae: 2.2130 - val_loss: 5.6652 - val_mae: 1.7038\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.2000 - mae: 1.9352 - val_loss: 5.8018 - val_mae: 1.7631\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6.9998 - mae: 2.0752 - val_loss: 6.5339 - val_mae: 1.9710\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 6.3927 - mae: 1.9691 - val_loss: 5.6737 - val_mae: 1.7094\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.8449 - mae: 2.2204 - val_loss: 14.3537 - val_mae: 3.3255\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 6.5145 - mae: 1.9509 - val_loss: 5.9201 - val_mae: 1.7144\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.7277 - mae: 1.8447\n",
      "Test loss : 6.727672100067139\n",
      "Test MAE : 1.844702124595642\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model creation\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)  \n",
    "])\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size_value, validation_data=(X_val, np.array(y_val)))\n",
    "\n",
    "# Evaluation\n",
    "loss, mae = model.evaluate(X_test, np.array(y_test))\n",
    "print(\"Test loss :\", loss)\n",
    "print(\"Test MAE :\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_next_date(date, hour):\n",
    "    \n",
    "    years = int(date.split(\"-\")[0])\n",
    "    months = int(date.split(\"-\")[1])\n",
    "    days = int(date.split(\"-\")[2])\n",
    "\n",
    "    return np.array([[years, months, days, hour]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "CSV file 'neural_network_prediction.csv' successfully created.\n"
     ]
    }
   ],
   "source": [
    "def predict_next_100_values(filename):\n",
    "    fields = [\"Id\", \"OT\"]\n",
    "\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(fields)\n",
    "        \n",
    "        for i in range(100):\n",
    "            csv_line = []\n",
    "            date = next_100_dates[i].split(\" \")[0]\n",
    "            hour = int(next_100_dates[i].split(\" \")[1].split(\":\")[0])\n",
    "            new_value_prediction = model.predict(preprocess_next_date(date, hour))\n",
    "            csv_line = [i, float(new_value_prediction)]\n",
    "            writer.writerow(csv_line)\n",
    "    print(f\"CSV file '{filename}' successfully created.\")\n",
    "\n",
    "filename = \"neural_network_prediction.csv\"\n",
    "predict_next_100_values(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
